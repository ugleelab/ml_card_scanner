import 'dart:async';
import 'dart:isolate';
import 'dart:ui';

import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:google_mlkit_text_recognition/google_mlkit_text_recognition.dart';
import 'package:ml_card_scanner/src/model/card_info.dart';
import 'package:ml_card_scanner/src/parser/parser_algorithm.dart';
import 'package:ml_card_scanner/src/utils/camera_image_util.dart';
import 'package:ml_card_scanner/src/utils/image_processor.dart';
import 'package:ml_card_scanner/src/utils/stream_debouncer.dart';

class ScannerProcessor {
  static const _kDebugOutputCooldownMillis = 5000;
  final bool _usePreprocessingFilters;
  final bool _debugOutputFilteredImage;
  final TextRecognizer _recognizer = TextRecognizer(
    script: TextRecognitionScript.latin,
  );
  StreamController<Uint8List>? _debugImageStreamController;

  ScannerProcessor({
    bool usePreprocessingFilters = false,
    bool debugOutputFilteredImage = false,
  })  : _usePreprocessingFilters = usePreprocessingFilters,
        _debugOutputFilteredImage = debugOutputFilteredImage {
    if (_debugOutputFilteredImage) {
      _debugImageStreamController = StreamController<Uint8List>.broadcast();
    }
  }

  Stream<Uint8List>? get imageStream =>
      _debugImageStreamController?.stream.transform(
        debounceTransformer(
          const Duration(milliseconds: _kDebugOutputCooldownMillis),
        ),
      );

  /// google_mlkit_commons ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ ìµœì í™”ëœ ì´ë¯¸ì§€ ì²˜ë¦¬
  Future<CardInfo?> computeImage(
    ParserAlgorithm parseAlgorithm,
    CameraImage image,
    InputImageRotation rotation,
  ) async {
    try {
      final inputImage = await _createInputImage(image, rotation);
      if (inputImage == null) return null;

      final recognizedText = await _recognizer.processImage(inputImage);

      if (kDebugMode) {
        _debugPrintRecognizedText(recognizedText);
      }

      final parsedCard = await parseAlgorithm.parse(recognizedText);
      return parsedCard;
    } catch (e) {
      if (kDebugMode) {
        debugPrint('Error processing image: $e');
      }
      return null;
    }
  }

  /// google_mlkit_commons ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ InputImage ìƒì„±
  Future<InputImage?> _createInputImage(
    CameraImage image,
    InputImageRotation rotation,
  ) async {
    // ì´ë¯¸ì§€ í¬ë§· ê²€ì¦ (google_mlkit_commons ê°€ì´ë“œë¼ì¸ ë”°ë¦„)
    final format = InputImageFormatValue.fromRawValue(image.format.raw);
    if (format == null) {
      if (kDebugMode) {
        debugPrint('Unsupported image format: ${image.format.raw}');
      }
      return null;
    }

    if (kDebugMode) {
      debugPrint(
          'ğŸ“¸ Camera image format detected: $format (raw: ${image.format.raw})');
      debugPrint(
          'ğŸ“ Image size: ${image.width}x${image.height}, planes: ${image.planes.length}');
    }

    // GitHub ì´ìŠˆ #145961 ëŒ€ì‘ ë¡œê·¸
    if (kDebugMode && defaultTargetPlatform == TargetPlatform.android) {
      if (format == InputImageFormat.yuv420 ||
          format == InputImageFormat.yuv_420_888) {
        debugPrint(
            'Android: Detected YUV420_888 format (${image.format.raw}), converting to nv21 for ML Kit');
      } else if (format == InputImageFormat.nv21) {
        debugPrint(
            'Android: Using nv21 format (${image.format.raw}) as expected');
      }
    }

    // í‰ë©´ ìˆ˜ ê¸°ë°˜ í¬ë§· ê²€ì¦ (ë” í™•ì‹¤í•œ ë°©ë²•)
    if (kDebugMode) {
      debugPrint('ğŸ” Format validation:');
      debugPrint('   Detected format: $format (raw: ${image.format.raw})');
      debugPrint('   Planes count: ${image.planes.length}');
      debugPrint('   Platform: ${defaultTargetPlatform}');
    }

    if (image.planes.length == 3) {
      // 3ê°œ í‰ë©´ = YUV420 ê³„ì—´ í¬ë§·
      if (kDebugMode) {
        debugPrint('âœ… 3-plane format detected - treating as YUV420_888');
      }

      // Androidì—ì„œ 3í‰ë©´ í¬ë§·ì€ YUV420_888ìœ¼ë¡œ ì²˜ë¦¬
      if (defaultTargetPlatform == TargetPlatform.android) {
        if (kDebugMode) {
          debugPrint('ğŸ”„ Will convert YUV420_888 to NV21 for ML Kit');
        }
      } else {
        if (kDebugMode) {
          debugPrint('âŒ YUV420_888 format not supported on iOS');
        }
        return null;
      }
    } else if (image.planes.length == 1) {
      // 1ê°œ í‰ë©´ = NV21 ë˜ëŠ” BGRA8888
      if (kDebugMode) {
        debugPrint('âœ… Single-plane format detected: $format');
      }

      // í”Œë«í¼ë³„ ë‹¨ì¼ í‰ë©´ í¬ë§· ê²€ì¦
      if (defaultTargetPlatform == TargetPlatform.android &&
          format != InputImageFormat.nv21) {
        if (kDebugMode) {
          debugPrint('âŒ Android requires NV21 format, got: $format');
        }
        return null;
      } else if (defaultTargetPlatform == TargetPlatform.iOS &&
          format != InputImageFormat.bgra8888) {
        if (kDebugMode) {
          debugPrint('âŒ iOS requires BGRA8888 format, got: $format');
        }
        return null;
      }
    } else {
      // ì§€ì›í•˜ì§€ ì•ŠëŠ” í‰ë©´ ìˆ˜
      if (kDebugMode) {
        debugPrint('âŒ Unsupported plane count: ${image.planes.length}');
      }
      return null;
    }

    if (!_usePreprocessingFilters) {
      // í‘œì¤€ ë°©ì‹: ì§ì ‘ ë°”ì´íŠ¸ ì‚¬ìš© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
      return _createStandardInputImage(image, format, rotation);
    } else {
      // ì „ì²˜ë¦¬ í•„í„° ì‚¬ìš© (Isolateì—ì„œ ì²˜ë¦¬) - ë‹¨ì¼ í‰ë©´ë§Œ ì§€ì›
      if (image.planes.length != 1) {
        if (kDebugMode) {
          debugPrint(
              'âŒ Preprocessing filters only support single-plane formats');
        }
        return null;
      }
      final plane = image.planes.first;
      return _createPreprocessedInputImage(image, plane, format, rotation);
    }
  }

  /// í‘œì¤€ InputImage ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
  InputImage _createStandardInputImage(
    CameraImage image,
    InputImageFormat format,
    InputImageRotation rotation,
  ) {
    // GitHub ì´ìŠˆ #145961 ëŒ€ì‘: 3ê°œ í‰ë©´ = YUV420_888ì„ ì‹¤ì œ NV21 ë°ì´í„°ë¡œ ë³€í™˜
    if (defaultTargetPlatform == TargetPlatform.android &&
        image.planes.length == 3) {
      try {
        if (kDebugMode) {
          debugPrint(
              'ğŸ”„ Converting 3-plane YUV420_888 to NV21 for ML Kit processing');
        }

        final nv21Data = CameraImageUtil.convertYUV420ToNV21(image);

        return InputImage.fromBytes(
          bytes: nv21Data,
          metadata: InputImageMetadata(
            size: Size(image.width.toDouble(), image.height.toDouble()),
            rotation: rotation,
            format: InputImageFormat.nv21,
            bytesPerRow: image.width,
          ),
        );
      } catch (e) {
        if (kDebugMode) {
          debugPrint('âŒ Failed to convert YUV420_888 to NV21: $e');
        }
        // ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²˜ë¦¬ë¡œ fallback
      }
    }

    // ê¸°ë³¸ ì²˜ë¦¬ (ë‹¨ì¼ í‰ë©´: NV21 ë˜ëŠ” BGRA8888) ë˜ëŠ” ë³€í™˜ ì‹¤íŒ¨ ì‹œ fallback
    final plane = image.planes.first;
    return InputImage.fromBytes(
      bytes: plane.bytes,
      metadata: InputImageMetadata(
        size: Size(image.width.toDouble(), image.height.toDouble()),
        rotation: rotation,
        format: format,
        bytesPerRow: plane.bytesPerRow,
      ),
    );
  }

  /// ì „ì²˜ë¦¬ê°€ í¬í•¨ëœ InputImage ìƒì„±
  Future<InputImage> _createPreprocessedInputImage(
    CameraImage image,
    Plane plane,
    InputImageFormat format,
    InputImageRotation rotation,
  ) async {
    final rawFormat = image.format.raw;
    final rawRotation = rotation.rawValue;
    final bytes = plane.bytes;
    final width = image.width;
    final height = image.height;
    final bytesPerRow = plane.bytesPerRow;

    ReceivePort? receivePort;
    if (_debugOutputFilteredImage) {
      receivePort = ReceivePort();
      receivePort.listen(
        (message) {
          if (message is Uint8List) {
            if (_debugImageStreamController != null &&
                !_debugImageStreamController!.isClosed) {
              _debugImageStreamController?.add(message);
            }
          }
        },
      );
    }

    final inputImage = await createInputImageInIsolate(
      rawBytes: bytes,
      width: width,
      height: height,
      rawRotation: rawRotation,
      rawFormat: rawFormat,
      bytesPerRow: bytesPerRow,
      debugSendPort: receivePort?.sendPort,
    );

    receivePort?.close();
    return inputImage;
  }

  /// ë””ë²„ê·¸ìš© ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì¶œë ¥
  void _debugPrintRecognizedText(RecognizedText recognizedText) {
    debugPrint('\n=== Recognized Text ===');
    debugPrint('Full Text: ${recognizedText.text}');
    debugPrint('Blocks (${recognizedText.blocks.length}):');
    for (int i = 0; i < recognizedText.blocks.length; i++) {
      final block = recognizedText.blocks[i];
      debugPrint('  Block $i: "${block.text.trim()}"');
      debugPrint('    Bounds: ${block.boundingBox}');
      if (block.recognizedLanguages.isNotEmpty) {
        debugPrint('    Languages: ${block.recognizedLanguages.join(", ")}');
      }
    }
    debugPrint('======================\n');
  }

  void dispose() {
    if (_debugImageStreamController != null &&
        !_debugImageStreamController!.isClosed) {
      _debugImageStreamController?.close();
    }
    unawaited(_recognizer.close());
  }
}
