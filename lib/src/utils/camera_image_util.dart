import 'dart:io';
import 'dart:typed_data';

import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:flutter/services.dart';
import 'package:google_mlkit_text_recognition/google_mlkit_text_recognition.dart';

/// google_mlkit_commons ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ ì¹´ë©”ë¼ ì´ë¯¸ì§€ ìœ í‹¸ë¦¬í‹°
class CameraImageUtil {
  static const Map<DeviceOrientation, int> _orientations = {
    DeviceOrientation.portraitUp: 0,
    DeviceOrientation.landscapeLeft: 90,
    DeviceOrientation.portraitDown: 180,
    DeviceOrientation.landscapeRight: 270,
  };

  /// google_mlkit_commons ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ ì´ë¯¸ì§€ íšŒì „ ê³„ì‚°
  ///
  /// Androidì™€ iOSì—ì„œ ë‹¤ë¥´ê²Œ ì²˜ë¦¬ë˜ëŠ” íšŒì „ ë¡œì§ì„ ì •í™•íˆ êµ¬í˜„
  static InputImageRotation? getImageRotation(
    int sensorOrientation,
    DeviceOrientation deviceOrientation,
    CameraLensDirection lensDirection,
  ) {
    InputImageRotation? rotation;

    if (Platform.isIOS) {
      // iOS: sensorOrientation ê°’ì„ ì§ì ‘ ì‚¬ìš©
      rotation = InputImageRotationValue.fromRawValue(sensorOrientation);
    } else if (Platform.isAndroid) {
      // Android: ë””ë°”ì´ìŠ¤ ë°©í–¥ê³¼ ì„¼ì„œ ë°©í–¥ì„ ì¡°í•©í•˜ì—¬ ê³„ì‚°
      var rotationCompensation = _orientations[deviceOrientation];
      if (rotationCompensation == null) {
        if (kDebugMode) {
          debugPrint('Unknown device orientation: $deviceOrientation');
        }
        return null;
      }

      if (lensDirection == CameraLensDirection.front) {
        // ì „ë©´ ì¹´ë©”ë¼: ì„¼ì„œ ë°©í–¥ + ë””ë°”ì´ìŠ¤ ë°©í–¥
        rotationCompensation = (sensorOrientation + rotationCompensation) % 360;
      } else {
        // í›„ë©´ ì¹´ë©”ë¼: ì„¼ì„œ ë°©í–¥ - ë””ë°”ì´ìŠ¤ ë°©í–¥
        rotationCompensation =
            (sensorOrientation - rotationCompensation + 360) % 360;
      }

      rotation = InputImageRotationValue.fromRawValue(rotationCompensation);
    }

    if (rotation == null && kDebugMode) {
      debugPrint(
          'Failed to determine rotation for platform: ${Platform.operatingSystem}');
    }

    return rotation;
  }

  /// InputImage ìƒì„±ì„ ìœ„í•œ ì´ë¯¸ì§€ í¬ë§· ê²€ì¦
  static bool isImageFormatSupported(int rawFormat) {
    final format = InputImageFormatValue.fromRawValue(rawFormat);
    if (format == null) return false;

    // google_mlkit_commons ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ í”Œë«í¼ë³„ ì§€ì› í¬ë§·
    if (Platform.isAndroid) {
      // GitHub ì´ìŠˆ #145961: camera_android_cameraxì—ì„œ nv21 ì„¤ì •í•´ë„ yuv_420_888 ë°˜í™˜ë˜ëŠ” ë²„ê·¸ ëŒ€ì‘
      return format == InputImageFormat.nv21 ||
          format == InputImageFormat.yuv420 ||
          format == InputImageFormat.yuv_420_888;
    } else if (Platform.isIOS) {
      return format == InputImageFormat.bgra8888;
    }

    return false;
  }

  /// Androidì—ì„œ yuv_420_888ì„ nv21ë¡œ ë³€í™˜ í•„ìš” ì—¬ë¶€ í™•ì¸
  static bool needsFormatConversion(int rawFormat) {
    if (!Platform.isAndroid) return false;
    final format = InputImageFormatValue.fromRawValue(rawFormat);
    return format == InputImageFormat.yuv420 ||
        format == InputImageFormat.yuv_420_888;
  }

  /// Androidì—ì„œ ì‚¬ìš©í•˜ëŠ” í”Œë«í¼ ì²´í¬
  static bool isAndroid() => Platform.isAndroid;

  /// YUV420_888 í¬ë§·ì„ NV21 í¬ë§·ìœ¼ë¡œ ë³€í™˜
  /// GitHub ì´ìŠˆ #145961 ëŒ€ì‘ì„ ìœ„í•œ ì‹¤ì œ ë°ì´í„° ë³€í™˜
  static Uint8List convertYUV420ToNV21(CameraImage image) {
    final width = image.width;
    final height = image.height;

    // YUV420_888 í¬ë§· ê²€ì¦
    if (image.planes.length != 3) {
      throw ArgumentError(
          'YUV420_888 format requires exactly 3 planes, got ${image.planes.length}');
    }

    // Planes from CameraImage
    final yPlane = image.planes[0];
    final uPlane = image.planes[1];
    final vPlane = image.planes[2];

    // Buffers from Y, U, and V planes
    final yBuffer = yPlane.bytes;
    final uBuffer = uPlane.bytes;
    final vBuffer = vPlane.bytes;

    // Total number of pixels in NV21 format
    final numPixels = width * height + (width * height ~/ 2);
    final nv21 = Uint8List(numPixels);

    // Y (Luma) plane metadata
    int idY = 0;
    int idUV = width * height; // Start UV after Y plane
    final uvWidth = width ~/ 2;
    final uvHeight = height ~/ 2;

    // Strides and pixel strides for Y and UV planes
    final yRowStride = yPlane.bytesPerRow;
    final yPixelStride = yPlane.bytesPerPixel ?? 1;
    final uvRowStride = uPlane.bytesPerRow;
    final uvPixelStride = uPlane.bytesPerPixel ?? 2;

    if (kDebugMode) {
      debugPrint(
          'ğŸ”„ Converting YUV420_888 (format code: ${image.format.raw}) to NV21:');
      debugPrint('   Image size: ${width}x$height');
      debugPrint(
          '   Y plane: stride=$yRowStride, pixelStride=$yPixelStride, bytes=${yBuffer.length}');
      debugPrint(
          '   U plane: stride=$uvRowStride, pixelStride=$uvPixelStride, bytes=${uBuffer.length}');
      debugPrint(
          '   V plane: stride=${vPlane.bytesPerRow}, pixelStride=${vPlane.bytesPerPixel ?? 2}, bytes=${vBuffer.length}');
      debugPrint('   Target NV21 size: $numPixels bytes');
    }

    // Copy Y (Luma) channel
    for (int y = 0; y < height; ++y) {
      final yOffset = y * yRowStride;
      for (int x = 0; x < width; ++x) {
        nv21[idY++] = yBuffer[yOffset + x * yPixelStride];
      }
    }

    // Copy UV (Chroma) channels in NV21 format (YYYYVU interleaved)
    for (int y = 0; y < uvHeight; ++y) {
      final uvOffset = y * uvRowStride;
      for (int x = 0; x < uvWidth; ++x) {
        final bufferIndex = uvOffset + (x * uvPixelStride);
        nv21[idUV++] = vBuffer[bufferIndex]; // V channel
        nv21[idUV++] = uBuffer[bufferIndex]; // U channel
      }
    }

    if (kDebugMode) {
      debugPrint('âœ… YUV420_888 to NV21 conversion completed successfully');
    }

    return nv21;
  }

  /// ì¹´ë©”ë¼ ì´ë¯¸ì§€ì—ì„œ InputImage ìƒì„± (ì‹¤ì œ ë°ì´í„° ë³€í™˜ í¬í•¨)
  static InputImage? inputImageFromCameraImage(
    CameraImage image,
    int sensorOrientation,
    DeviceOrientation deviceOrientation,
    CameraLensDirection lensDirection,
  ) {
    // íšŒì „ ê³„ì‚°
    final rotation = getImageRotation(
      sensorOrientation,
      deviceOrientation,
      lensDirection,
    );
    if (rotation == null) return null;

    // ì´ë¯¸ì§€ í¬ë§· ê²€ì¦
    final format = InputImageFormatValue.fromRawValue(image.format.raw);
    if (format == null || !isImageFormatSupported(image.format.raw)) {
      return null;
    }

    // GitHub ì´ìŠˆ #145961 ëŒ€ì‘: YUV420_888ì„ ì‹¤ì œ NV21 ë°ì´í„°ë¡œ ë³€í™˜
    if (isAndroid() &&
        (format == InputImageFormat.yuv420 ||
            format == InputImageFormat.yuv_420_888)) {
      try {
        final nv21Data = convertYUV420ToNV21(image);

        return InputImage.fromBytes(
          bytes: nv21Data,
          metadata: InputImageMetadata(
            size: Size(image.width.toDouble(), image.height.toDouble()),
            rotation: rotation,
            format: InputImageFormat.nv21,
            bytesPerRow: image.width, // NV21 í¬ë§·ì˜ bytes per row
          ),
        );
      } catch (e) {
        if (kDebugMode) {
          debugPrint('âŒ Failed to convert YUV420_888 to NV21: $e');
        }
        return null;
      }
    }

    // ê¸°ë³¸ ì²˜ë¦¬ (NV21 ë˜ëŠ” BGRA8888)
    if (image.planes.length != 1) return null;
    final plane = image.planes.first;

    return InputImage.fromBytes(
      bytes: plane.bytes,
      metadata: InputImageMetadata(
        size: Size(image.width.toDouble(), image.height.toDouble()),
        rotation: rotation,
        format: format,
        bytesPerRow: plane.bytesPerRow,
      ),
    );
  }

  const CameraImageUtil._();
}
